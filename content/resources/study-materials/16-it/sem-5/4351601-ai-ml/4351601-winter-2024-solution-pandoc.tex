\documentclass[10pt,a4paper]{article}
\input{../../../../../../latex-templates/gtu-solutions/preamble.tex}
\input{../../../../../../latex-templates/gtu-solutions/english-boxes.tex}

\begin{document}

\begin{center}
{\Huge\bfseries\color{headcolor} Subject Name Solutions}\\[5pt]
{\LARGE 4351601 -- Winter 2024}\\[3pt]
{\large Semester 1 Study Material}\\[3pt]
{\normalsize\textit{Detailed Solutions and Explanations}}
\end{center}

\vspace{10pt}

\subsection*{Question 1(a) [3 marks]}\label{q1a}

\textbf{Define following terms: 1) Fuzzy Logic. 2) Expert System.}

\begin{solutionbox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.6667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Fuzzy Logic} & Computing approach that deals with approximate
rather than fixed and exact reasoning, allowing degrees of truth between
0 and 1 \\
\textbf{Expert System} & AI program that mimics human expert
decision-making by using knowledge base and inference engine to solve
specific problems \\
\end{longtable}
}

\begin{itemize}
\tightlist
\item
  \textbf{Key Features}: Both handle uncertainty and incomplete
  information
\item
  \textbf{Applications}: Medical diagnosis, industrial control systems
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``Fuzzy Experts handle uncertain decisions''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 1(b) [4 marks]}\label{q1b}

\textbf{Define following terms: 1) Machine Learning. 2) Reinforcement
Learning.}

\begin{solutionbox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1622}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3243}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5135}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Characteristic
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Machine Learning} & Algorithm that automatically improves
performance through experience without explicit programming & Learning
from data patterns \\
\textbf{Reinforcement Learning} & Agent learns optimal actions through
trial-and-error interactions with environment using rewards/penalties &
Learning through feedback \\
\end{longtable}
}

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph LR
    A[Data] {-{-}{} B[ML Algorithm] {-}{-}{} C[Model] {-}{-}{} D[Predictions]}
    E[Environment] {-{-}{} F[RL Agent] {-}{-}{} G[Actions] {-}{-}{} E}
    E {-{-}{} H[Rewards] {-}{-}{} F}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\end{solutionbox}
\begin{mnemonicbox}
``ML learns from Data, RL learns from Rewards''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 1(c) [7 marks]}\label{q1c}

\textbf{Explain types of Artificial Intelligence in detail with suitable
diagram.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Types of AI}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1463}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3171}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2927}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2439}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Capability
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Examples
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Narrow AI} & Designed for specific tasks & Limited domain
expertise & Siri, Chess programs \\
\textbf{General AI} & Human-level intelligence across domains &
Multi-domain reasoning & Currently theoretical \\
\textbf{Super AI} & Exceeds human intelligence & Beyond human
capabilities & Future concept \\
\end{longtable}
}

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph TD
    A[Artificial Intelligence] {-{-}{} B[Narrow AI{}br/{}Weak AI]}
    A {-{-}{} C[General AI{}br/{}Strong AI]}
    A {-{-}{} D[Super AI]}
    
    B {-{-}{} E[Task{-}Specific{}br/{}Current Reality]}
    C {-{-}{} F[Human{-}Level{}br/{}Future Goal]}
    D {-{-}{} G[Beyond Human{}br/{}Theoretical]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\begin{itemize}
\tightlist
\item
  \textbf{Current Status}: We are in Narrow AI era
\item
  \textbf{Development Path}: Narrow \rightarrow General \rightarrow Super AI
\item
  \textbf{Timeline}: General AI expected in 20-30 years
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``Narrow Now, General Goal, Super Soon''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 1(c) OR [7
marks]}\label{q1c}

\textbf{Explain various aspects related to ethics while designing an AI
system. Also, explain limitations of AI system in detail.}

\begin{solutionbox}

\textbf{AI Ethics Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Ethical Aspect & Description & Implementation \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Fairness} & Avoid bias and discrimination & Diverse training
data \\
\textbf{Transparency} & Explainable AI decisions & Clear algorithms \\
\textbf{Privacy} & Protect user data & Data encryption \\
\textbf{Accountability} & Responsibility for AI actions & Human
oversight \\
\end{longtable}
}

\textbf{AI Limitations:}

\begin{itemize}
\tightlist
\item
  \textbf{Data Dependency}: Requires large, quality datasets
\item
  \textbf{Lack of Common Sense}: Cannot understand context like humans
\item
  \textbf{Brittleness}: Fails in unexpected situations
\item
  \textbf{Black Box Problem}: Difficult to explain decisions
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``Fair, Transparent, Private, Accountable AI has
Data, Common sense, Brittleness, Black box issues''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 2(a) [3 marks]}\label{q2a}

\textbf{List characteristics of reinforcement learning.}

\begin{solutionbox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5517}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4483}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Characteristic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Trial-and-Error} & Agent learns through experimentation \\
\textbf{Reward-Based} & Feedback through rewards/penalties \\
\textbf{Sequential Decision Making} & Actions affect future states \\
\textbf{Exploration vs Exploitation} & Balance between trying new
actions and using known good actions \\
\end{longtable}
}

\end{solutionbox}
\begin{mnemonicbox}
``Trial Rewards Sequential Exploration''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 2(b) [4 marks]}\label{q2b}

\textbf{Explain positive reinforcement and negative reinforcement.}

\begin{solutionbox}

\textbf{Comparison Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1714}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2286}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2571}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Effect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Positive Reinforcement} & Adding pleasant stimulus to increase
behavior & Increases desired behavior & Giving treat for good
performance \\
\textbf{Negative Reinforcement} & Removing unpleasant stimulus to
increase behavior & Increases desired behavior & Stopping alarm when
task completed \\
\end{longtable}
}

\textbf{Key Difference}: Both increase behavior, but positive adds
reward while negative removes punishment.

\end{solutionbox}
\begin{mnemonicbox}
``Positive Adds pleasure, Negative Removes pain''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 2(c) [7 marks]}\label{q2c}

\textbf{Explain Supervised learning in detail.}

\begin{solutionbox}

\textbf{Definition}: Learning algorithm that learns from labeled
training data to make predictions on new data.

\textbf{Process Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4643}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3214}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Training} & Algorithm learns from input-output pairs & Email \rightarrow
Spam/Not Spam \\
\textbf{Validation} & Test model on unseen data & Check accuracy \\
\textbf{Prediction} & Make outputs for new inputs & Classify new
emails \\
\end{longtable}
}

\textbf{Types:}

\begin{itemize}
\tightlist
\item
  \textbf{Classification}: Predicts categories (spam detection)
\item
  \textbf{Regression}: Predicts continuous values (house prices)
\end{itemize}

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph LR
    A[Training Data{br/{}X,Y pairs] {-}{-}{} B[Learning Algorithm] {-}{-}{} C[Model]}
    D[New Input X] {-{-}{} C {-}{-}{} E[Prediction Y]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\end{solutionbox}
\begin{mnemonicbox}
``Supervised = Teacher provides correct answers''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 2(a) OR [3
marks]}\label{q2a}

\textbf{List key components involved in human learning.}

\begin{solutionbox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Component & Function \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Observation} & Gathering information from environment \\
\textbf{Memory} & Storing and retrieving experiences \\
\textbf{Practice} & Repetition to improve skills \\
\textbf{Feedback} & Information about performance \\
\end{longtable}
}

\end{solutionbox}
\begin{mnemonicbox}
``Observe, Memorize, Practice, Feedback''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 2(b) OR [4
marks]}\label{q2b}

\textbf{Explain about well-posed learning problem in detail.}

\begin{solutionbox}

\textbf{Definition}: A learning problem with clearly defined task,
performance measure, and experience.

\textbf{Components Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Component & Description & Example \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Task (T)} & What the system should learn to do & Play chess \\
\textbf{Performance (P)} & How to measure success & Win percentage \\
\textbf{Experience (E)} & Training data or practice & Previous games \\
\end{longtable}
}

\textbf{Formula}: Learning = Improving P on T through E

\textbf{Criteria}: Problem must be measurable, achievable, and have
available data.

\end{solutionbox}
\begin{mnemonicbox}
``Task Performance Experience = TPE for learning''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 2(c) OR [7
marks]}\label{q2c}

\textbf{Explain Unsupervised learning in detail.}

\begin{solutionbox}

\textbf{Definition}: Learning patterns from data without labeled
examples or target outputs.

\textbf{Types Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1714}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2571}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2571}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Clustering} & Group similar data & K-means & Customer
segmentation \\
\textbf{Association} & Find relationships & Apriori & Market basket
analysis \\
\textbf{Dimensionality Reduction} & Reduce features & PCA & Data
visualization \\
\end{longtable}
}

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph TD
    A[Unlabeled Data] {-{-}{} B[Unsupervised Algorithm]}
    B {-{-}{} C[Clustering]}
    B {-{-}{} D[Association Rules]}
    B {-{-}{} E[Dimensionality Reduction]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\begin{itemize}
\tightlist
\item
  \textbf{No Teacher}: Algorithm finds hidden patterns independently
\item
  \textbf{Exploratory}: Discovers unknown structures in data
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``Unsupervised = No teacher, find patterns yourself''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 3(a) [3 marks]}\label{q3a}

\textbf{Explain SIGMOID function. Also, draw its graph and provide an
example of SIGMOID function.}

\begin{solutionbox}

\textbf{Definition}: Activation function that maps any real number to
value between 0 and 1.

\textbf{Formula}: σ(x) = 1/(1 + e\^{}(-x))

\textbf{Graph (ASCII):}

\begin{verbatim}
    1 |     .\_{-}
      |   .{-}
    0.5|.{-}
      |{}
    0 +{-{-}{-}{-}{-}{-}{-}{-}{-}{-}}
     {-5  0   5}
\end{verbatim}

\textbf{Example}: For x = 0, σ(0) = 1/(1 + e\^{}0) = 1/2 = 0.5

\textbf{Properties}: S-shaped curve, smooth gradient, used in binary
classification

\end{solutionbox}
\begin{mnemonicbox}
``Sigmoid Squashes values between 0 and 1''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 3(b) [4 marks]}\label{q3b}

\textbf{Define following term: 1) Activation function. 2) Artificial
neural network.}

\begin{solutionbox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4444}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Activation Function} & Mathematical function that determines
neuron output based on weighted inputs & Introduces non-linearity to
neural networks \\
\textbf{Artificial Neural Network} & Computing system inspired by
biological neural networks with interconnected nodes & Pattern
recognition and machine learning \\
\end{longtable}
}

\textbf{Key Features:}

\begin{itemize}
\tightlist
\item
  \textbf{Non-linear processing} enables complex pattern learning
\item
  \textbf{Layered architecture} processes information hierarchically
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``Activation Artificially mimics brain neurons''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 3(c) [7 marks]}\label{q3c}

\textbf{Draw and explain architecture of Recurrent network in detail.}

\begin{solutionbox}

\textbf{Definition}: Neural network with connections that create loops,
allowing information persistence.

\textbf{Architecture Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph LR
    A[Input x\_t] {-{-}{} B[Hidden State h\_t]}
    B {-{-}{} C[Output y\_t]}
    B {-{-}{} D[Hidden State h\_t+1]}
    E[Previous State h\_t{-1] {-}{-}{} B}
    
    subgraph "Time Steps"
    direction LR
    F[t{-1] {-}{-}{} G[t] {-}{-}{} H[t+1]}
    end
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\textbf{Components Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Function
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Hidden State} & Memory of previous inputs & h\_t = f(W\_h
\emph{h\_t-1 + W\_x} x\_t) \\
\textbf{Input Layer} & Current time step input & x\_t \\
\textbf{Output Layer} & Prediction at time t & y\_t = W\_y * h\_t \\
\end{longtable}
}

\textbf{Applications}: Speech recognition, language translation, time
series prediction

\textbf{Advantage}: Handles sequential data with memory of past
information

\end{solutionbox}
\begin{mnemonicbox}
``Recurrent = Remembers previous states''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 3(a) OR [3
marks]}\label{q3a}

\textbf{Explain TANH function. Also, draw its graph and provide an
example of TANH function.}

\begin{solutionbox}

\textbf{Definition}: Hyperbolic tangent activation function that maps
values between -1 and 1.

\textbf{Formula}: tanh(x) = (e\^{}x - e\textsuperscript{(-x))/(e}x +
e\^{}(-x))

\textbf{Graph (ASCII):}

\begin{verbatim}
    1 |      .\_{-}
      |    .{-}
    0 +.{-{-}{-}{-}{-}{-}{-}{-}}
      |.{-}
   {-1 |}
      +{-{-}{-}{-}{-}{-}{-}{-}{-}{-}}
     {-3  0   3}
\end{verbatim}

\textbf{Example}: For x = 0, tanh(0) = (1-1)/(1+1) = 0

\textbf{Properties}: Zero-centered, S-shaped, stronger gradients than
sigmoid

\end{solutionbox}
\begin{mnemonicbox}
``TANH = Two-sided sigmoid (-1 to +1)''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 3(b) OR [4
marks]}\label{q3b}

\textbf{Define following term: 1) Biological neural network. 2) Loss
calculation.}

\begin{solutionbox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1935}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3871}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4194}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Aspects
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Biological Neural Network} & Network of interconnected neurons
in living organisms that process information & Dendrites, cell body,
axon, synapses \\
\textbf{Loss calculation} & Mathematical measure of difference between
predicted and actual outputs & Guides learning through
backpropagation \\
\end{longtable}
}

\textbf{Biological Structure}: Neurons \rightarrow Synapses \rightarrow Neural Networks \rightarrow
Brain \textbf{Loss Types}: Mean Squared Error, Cross-entropy, Absolute
Error

\end{solutionbox}
\begin{mnemonicbox}
``Biology inspires AI, Loss measures learning
progress''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 3(c) OR [7
marks]}\label{q3c}

\textbf{Draw and explain architecture of multi-layer feed-forward
network in detail.}

\begin{solutionbox}

\textbf{Definition}: Neural network with multiple layers where
information flows forward from input to output.

\textbf{Architecture Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph LR
    subgraph "Input Layer"
    A1[x1] 
    A2[x2]
    A3[x3]
    end
    
    subgraph "Hidden Layer 1"
    B1[h1]
    B2[h2]
    B3[h3]
    end
    
    subgraph "Hidden Layer 2"
    C1[h4]
    C2[h5]
    end
    
    subgraph "Output Layer"
    D1[y1]
    D2[y2]
    end
    
    A1 {-{-}{} B1}
    A1 {-{-}{} B2}
    A2 {-{-}{} B1}
    A2 {-{-}{} B3}
    A3 {-{-}{} B2}
    A3 {-{-}{} B3}
    
    B1 {-{-}{} C1}
    B2 {-{-}{} C1}
    B2 {-{-}{} C2}
    B3 {-{-}{} C2}
    
    C1 {-{-}{} D1}
    C1 {-{-}{} D2}
    C2 {-{-}{} D1}
    C2 {-{-}{} D2}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\textbf{Layer Functions Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Layer & Function & Processing \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Input} & Receives data & No processing, just distribution \\
\textbf{Hidden} & Feature extraction & Weighted sum + activation
function \\
\textbf{Output} & Final prediction & Classification or regression
output \\
\end{longtable}
}

\textbf{Information Flow}: Input \rightarrow Hidden Layer(s) \rightarrow Output
(unidirectional) \textbf{Learning}: Backpropagation adjusts weights
based on error

\end{solutionbox}
\begin{mnemonicbox}
``Multi-layer = Multiple hidden layers for complex
learning''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 4(a) [3 marks]}\label{q4a}

\textbf{List advantages of NLP in detail.}

\begin{solutionbox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4583}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5417}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Advantage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Automation} & Automates text processing tasks that require human
effort \\
\textbf{Language Understanding} & Processes multiple languages and
dialects effectively \\
\textbf{24/7 Availability} & Works continuously without human
intervention \\
\textbf{Scalability} & Handles large volumes of text data efficiently \\
\end{longtable}
}

\textbf{Applications}: Chatbots, translation, sentiment analysis,
document processing

\end{solutionbox}
\begin{mnemonicbox}
``NLP = Automates Language Understanding 24/7 at
Scale''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 4(b) [4 marks]}\label{q4b}

\textbf{Explain Natural Language Generation in detail.}

\begin{solutionbox}

\textbf{Definition}: AI process that converts structured data into
natural human language text.

\textbf{Process Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2069}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4483}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3448}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Function
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Content Planning} & Decide what information to include & Data
selection \\
\textbf{Sentence Planning} & Structure sentences and paragraphs & Text
organization \\
\textbf{Surface Realization} & Generate actual text with grammar & Final
output \\
\end{longtable}
}

\textbf{Applications}: Report generation, chatbots, automated
journalism, personalized content

\textbf{Example}: Converting sales data \rightarrow ``Sales increased 15\% this
quarter due to strong performance in electronics.''

\end{solutionbox}
\begin{mnemonicbox}
``NLG = Numbers to Narrative''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 4(c) [7 marks]}\label{q4c}

\textbf{Explain types of ambiguities in NLP. Also, provide examples of
each ambiguity.}

\begin{solutionbox}

\textbf{Ambiguity Types Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1538}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2308}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2821}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Resolution
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Lexical} & Word has multiple meanings & ``Bank''
(river/financial) & Context analysis \\
\textbf{Syntactic} & Sentence structure unclear & ``I saw man with
telescope'' & Parse trees \\
\textbf{Semantic} & Meaning unclear & ``Colorless green ideas'' &
Semantic rules \\
\textbf{Pragmatic} & Context-dependent meaning & ``Can you pass salt?''
(request/question) & Situational context \\
\end{longtable}
}

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph TD
    A[NLP Ambiguities] {-{-}{} B[Lexical{}br/{}Word Level]}
    A {-{-}{} C[Syntactic{}br/{}Grammar Level]}
    A {-{-}{} D[Semantic{}br/{}Meaning Level]}
    A {-{-}{} E[Pragmatic{}br/{}Context Level]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\textbf{Resolution Strategies}: Context analysis, statistical models,
knowledge bases

\end{solutionbox}
\begin{mnemonicbox}
``Lexical Syntactic Semantic Pragmatic = LSSP
ambiguities''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 4(a) OR [3
marks]}\label{q4a}

\textbf{List disadvantages of NLP in detail.}

\begin{solutionbox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5185}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4815}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Disadvantage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Context Limitations} & Struggles with sarcasm, humor, cultural
references \\
\textbf{Language Complexity} & Difficulty with idioms, slang, regional
dialects \\
\textbf{Data Requirements} & Needs large amounts of training data \\
\textbf{Computational Cost} & Requires significant processing power and
memory \\
\end{longtable}
}

\textbf{Challenges}: Ambiguity, multilingual support, real-time
processing

\end{solutionbox}
\begin{mnemonicbox}
``NLP Challenges = Context, Language, Data,
Computation''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 4(b) OR [4
marks]}\label{q4b}

\textbf{Explain Natural Language Understanding in detail.}

\begin{solutionbox}

\textbf{Definition}: AI capability to comprehend and interpret human
language meaning and intent.

\textbf{Components Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Function
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Tokenization} & Break text into words/phrases & ``Hello world''
\rightarrow [``Hello'', ``world''] \\
\textbf{Parsing} & Analyze grammatical structure & Identify subject,
verb, object \\
\textbf{Semantic Analysis} & Extract meaning & Understand relationships
between words \\
\textbf{Intent Recognition} & Identify user purpose & ``Book flight'' \rightarrow
travel booking intent \\
\end{longtable}
}

\textbf{Process Flow}: Text Input \rightarrow Tokenization \rightarrow Parsing \rightarrow Semantic
Analysis \rightarrow Intent Understanding

\textbf{Applications}: Virtual assistants, chatbots, voice commands

\end{solutionbox}
\begin{mnemonicbox}
``NLU = Naturally Understands Language''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 4(c) OR [7
marks]}\label{q4c}

\textbf{Explain stemming and lemmatization in detail. Also provide two
examples of each.}

\begin{solutionbox}

\textbf{Definitions:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2250}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Process
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Stemming} & Reduces words to root form by removing suffixes &
Rule-based chopping & Word stem \\
\textbf{Lemmatization} & Reduces words to dictionary base form &
Dictionary lookup & Valid word \\
\end{longtable}
}

\textbf{Stemming Examples:}

\begin{enumerate}
\tightlist
\item
  ``running'', ``runs'', ``ran'' \rightarrow ``run''
\item
  ``fishing'', ``fished'', ``fisher'' \rightarrow ``fish''
\end{enumerate}

\textbf{Lemmatization Examples:}

\begin{enumerate}
\tightlist
\item
  ``better'' \rightarrow ``good'' (comparative to base)
\item
  ``children'' \rightarrow ``child'' (plural to singular)
\end{enumerate}

\textbf{Comparison Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Aspect & Stemming & Lemmatization \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Speed} & Faster & Slower \\
\textbf{Accuracy} & Lower & Higher \\
\textbf{Output} & May not be valid word & Always valid word \\
\end{longtable}
}

\end{solutionbox}
\begin{mnemonicbox}
``Stemming = Speed, Lemmatization = Language
accuracy''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 5(a) [3 marks]}\label{q5a}

\textbf{Define: 1) Word embeddings. 2) Machine Translation.}

\begin{solutionbox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4444}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Term
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Word Embeddings} & Dense vector representations of words that
capture semantic relationships & Convert text to numerical form for
ML \\
\textbf{Machine Translation} & Automated conversion of text from one
language to another & Enable cross-language communication \\
\end{longtable}
}

\textbf{Key Features}:

\begin{itemize}
\tightlist
\item
  \textbf{Word embeddings} preserve word relationships in vector space
\item
  \textbf{Machine translation} maintains meaning across languages
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``Words become Vectors, Languages become
Translations''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 5(b) [4 marks]}\label{q5b}

\textbf{Explain Word2Vec in detail.}

\begin{solutionbox}

\textbf{Definition}: Neural network technique that creates word
embeddings by learning word associations from large text corpus.

\textbf{Architecture Types:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2188}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4062}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3750}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Model
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Prediction
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{CBOW (Continuous Bag of Words)} & Predicts target word from
context & Context \rightarrow Target \\
\textbf{Skip-gram} & Predicts context words from target & Target \rightarrow
Context \\
\end{longtable}
}

\textbf{Process}:

\begin{enumerate}
\tightlist
\item
  \textbf{Training}: Neural network learns word relationships
\item
  \textbf{Vector Creation}: Each word gets unique vector representation
\item
  \textbf{Similarity}: Similar words have similar vectors
\end{enumerate}

\textbf{Example}: vector(``king'') - vector(``man'') + vector(``woman'')
\approx vector(``queen'')

\end{solutionbox}
\begin{mnemonicbox}
``Word2Vec = Words to Vectors through Context''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 5(c) [7 marks]}\label{q5c}

\textbf{Consider that a manufacturer of a product has collected feedback
from the customer and is now willing to apply sentiment analysis on it.
What are the steps to be followed for the same? Explain in detail.}

\begin{solutionbox}

\textbf{Sentiment Analysis Pipeline:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1765}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3824}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4412}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Tools/Methods
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Data Collection} & Gather customer feedback & Surveys, reviews,
social media \\
\textbf{Data Preprocessing} & Clean and prepare text & Remove noise,
tokenization \\
\textbf{Feature Extraction} & Convert text to numerical & TF-IDF, Word
embeddings \\
\textbf{Model Training} & Train sentiment classifier & Naive Bayes, SVM,
Neural networks \\
\textbf{Prediction} & Classify sentiment & Positive/Negative/Neutral \\
\textbf{Analysis} & Interpret results & Generate insights and reports \\
\end{longtable}
}

\textbf{Implementation Flow:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph LR
    A[Customer Feedback] {-{-}{} B[Text Preprocessing]}
    B {-{-}{} C[Feature Extraction]}
    C {-{-}{} D[Sentiment Model]}
    D {-{-}{} E[Classification]}
    E {-{-}{} F[Business Insights]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\textbf{Preprocessing Steps:}

\begin{itemize}
\tightlist
\item
  \textbf{Remove special characters} and URLs
\item
  \textbf{Convert to lowercase} for consistency
\item
  \textbf{Remove stop words} (the, and, or)
\item
  \textbf{Handle negations} (not good \rightarrow negative sentiment)
\end{itemize}

\textbf{Model Evaluation}: Use metrics like accuracy, precision, recall,
F1-score

\textbf{Business Value}: Understand customer satisfaction, improve
products, identify issues

\end{solutionbox}
\begin{mnemonicbox}
``Collect, Clean, Extract, Train, Predict, Analyze =
Ccetpa''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 5(a) OR [3
marks]}\label{q5a}

\textbf{List out advantages of GloVe with respect to NLP.}

\begin{solutionbox}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4583}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5417}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Advantage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Global Context} & Considers entire corpus statistics, not just
local context \\
\textbf{Linear Relationships} & Captures semantic relationships through
vector arithmetic \\
\textbf{Efficiency} & Faster training compared to Word2Vec on large
datasets \\
\textbf{Stability} & Consistent results across multiple training runs \\
\end{longtable}
}

\textbf{Key Benefits}: Better performance on word analogy tasks,
captures both local and global statistics

\end{solutionbox}
\begin{mnemonicbox}
``GloVe = Global Vector Excellence''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 5(b) OR [4
marks]}\label{q5b}

\textbf{Explain challenges with TFIDF and BoW.}

\begin{solutionbox}

\textbf{Challenges Table:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2759}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4138}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3103}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Challenges
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Impact
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{TF-IDF} & 1. Ignores word order2. Sparse vectors3. No semantic
similarity & Limited context understanding \\
\textbf{BoW} & 1. Loses sequence information2. High dimensionality3. No
word relationships & Poor semantic representation \\
\end{longtable}
}

\textbf{Common Issues:}

\begin{itemize}
\tightlist
\item
  \textbf{Vocabulary size}: Creates very large, sparse matrices
\item
  \textbf{Out-of-vocabulary}: Cannot handle new words
\item
  \textbf{Semantic gap}: ``Good'' and ``excellent'' treated as different
\end{itemize}

\textbf{Solutions}: Use word embeddings (Word2Vec, GloVe) for dense,
semantic representations

\end{solutionbox}
\begin{mnemonicbox}
``TF-IDF and BoW = Sparse, No order, No semantics''

\end{mnemonicbox}
\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection*{Question 5(c) OR [7
marks]}\label{q5c}

\textbf{Consider that an e-mail service provider is willing to apply a
SPAM detection technique. What are the steps to be followed to detect a
SPAM e-mail? Explain in detail.}

\begin{solutionbox}

\textbf{SPAM Detection Pipeline:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1935}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4194}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3871}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Techniques
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Data Collection} & Gather labeled spam/ham emails & Email
datasets, user reports \\
\textbf{Feature Engineering} & Extract relevant features & Subject
analysis, sender patterns \\
\textbf{Text Preprocessing} & Clean email content & Remove HTML,
normalize text \\
\textbf{Feature Extraction} & Convert to numerical form & TF-IDF,
N-grams, metadata \\
\textbf{Model Training} & Train classifier & Naive Bayes, SVM, Random
Forest \\
\textbf{Validation} & Test model performance & Cross-validation, test
set \\
\textbf{Deployment} & Integrate with email system & Real-time
classification \\
\end{longtable}
}

\textbf{Feature Types:}

{\def\LTcaptype{none} % do not increment counter
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4865}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2703}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2432}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Feature Category
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Examples
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Content-based} & Keywords, phrases, HTML tags & Analyze email
body \\
\textbf{Header-based} & Sender, subject, timestamps & Check metadata \\
\textbf{Behavioral} & Sending patterns, frequency & Identify suspicious
behavior \\
\end{longtable}
}

\textbf{Implementation Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph LR
    A[Incoming Email] {-{-}{} B[Feature Extraction]}
    B {-{-}{} C\{SPAM Classifier\}}
    C {-{-}{}|Spam| D[Spam Folder]}
    C {-{-}{}|Ham| E[Inbox]}
    F[User Feedback] {-{-}{} G[Model Update]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\textbf{Model Evaluation Metrics:}

\begin{itemize}
\tightlist
\item
  \textbf{Precision}: Avoid false positives (legitimate emails marked as
  spam)
\item
  \textbf{Recall}: Catch actual spam emails
\item
  \textbf{F1-Score}: Balance between precision and recall
\end{itemize}

\textbf{Continuous Learning}: Update model with new spam patterns and
user feedback

\end{solutionbox}
\begin{mnemonicbox}
``Collect, Engineer, Process, Extract, Train,
Validate, Deploy = CEPTVD''

\end{mnemonicbox}

\end{document}

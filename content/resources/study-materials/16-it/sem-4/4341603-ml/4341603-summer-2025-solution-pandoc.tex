\documentclass[10pt,a4paper]{article}
\input{../../../../../../latex-templates/gtu-solutions/preamble.tex}
\input{../../../../../../latex-templates/gtu-solutions/english-boxes.tex}

\begin{document}

\begin{center}
{\Huge\bfseries\color{headcolor} Subject Name Solutions}\\[5pt]
{\LARGE 4341603 -- Summer 2025}\\[3pt]
{\large Semester 1 Study Material}\\[3pt]
{\normalsize\textit{Detailed Solutions and Explanations}}
\end{center}

\vspace{10pt}

\subsection*{Question 1(a) [3 marks]}\label{q1a}

\textbf{Define machine Learning. Give any two applications of machine
learning.}

\begin{solutionbox}

Machine Learning is a subset of artificial intelligence that enables
computers to learn and make decisions from data without being explicitly
programmed for every task.

\textbf{Applications:}

\begin{itemize}
\tightlist
\item
  \textbf{Email spam detection}: Automatically identifies and filters
  spam emails
\item
  \textbf{Recommendation systems}: Suggests products on e-commerce sites
  like Amazon
\end{itemize}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{ML vs Traditional Programming}
\vspace{-10pt}
\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Traditional Programming & Machine Learning \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Input data + Program \rightarrow Output & Input data + Output \rightarrow Program \\
Rules are explicitly coded & Rules are learned from data \\
\end{longtable}
}

\end{solutionbox}
\begin{mnemonicbox}
``ML = Make Learning from data''

\end{mnemonicbox}
\subsection*{Question 1(b) [4 marks]}\label{q1b}

\textbf{Define: Under fitting and overfitting.}

\begin{solutionbox}

\textbf{Underfitting} occurs when a model is too simple to capture
underlying patterns in data, resulting in poor performance on both
training and test data.

\textbf{Overfitting} occurs when a model learns training data too well,
including noise, causing poor performance on new unseen data.


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Comparison}
\vspace{-10pt}
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Aspect & Underfitting & Overfitting \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Training accuracy} & Low & High \\
\textbf{Test accuracy} & Low & Low \\
\textbf{Model complexity} & Too simple & Too complex \\
\textbf{Solution} & Increase complexity & Reduce complexity \\
\end{longtable}
}

\end{solutionbox}
\begin{mnemonicbox}
``Under = Under-performs, Over = Over-learns''

\end{mnemonicbox}
\subsection*{Question 1(c) [7 marks]}\label{q1c}

\textbf{Describe different types of machine learning with suitable
example.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Types of Machine Learning}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4643}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3214}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Supervised} & Uses labeled training data & Email
classification \\
\textbf{Unsupervised} & No labeled data, finds patterns & Customer
segmentation \\
\textbf{Reinforcement} & Learns through rewards/penalties & Game playing
AI \\
\end{longtable}
}

\textbf{Supervised Learning} uses input-output pairs to train models.
The algorithm learns from examples to predict outcomes for new data.

\textbf{Unsupervised Learning} discovers hidden patterns in data without
target labels. It groups similar data points together.

\textbf{Reinforcement Learning} trains agents to make decisions by
rewarding good actions and penalizing bad ones.

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph TD
    A[Machine Learning] {-{-}{} B[Supervised Learning]}
    A {-{-}{} C[Unsupervised Learning]}
    A {-{-}{} D[Reinforcement Learning]}
    B {-{-}{} E[Classification]}
    B {-{-}{} F[Regression]}
    C {-{-}{} G[Clustering]}
    C {-{-}{} H[Association Rules]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\end{solutionbox}
\begin{mnemonicbox}
``Super Un-supervised Reinforces learning''

\end{mnemonicbox}
\subsection*{Question 1(c) OR [7
marks]}\label{q1c}

\textbf{Describe different tools and technology used in the field
machine learning.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{ML Tools and Technologies}
\vspace{-10pt}
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Category & Tools & Purpose \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Programming} & Python, R & Core development \\
\textbf{Libraries} & Scikit-learn, TensorFlow & Model building \\
\textbf{Data Processing} & Pandas, NumPy & Data manipulation \\
\textbf{Visualization} & Matplotlib, Seaborn & Data plotting \\
\end{longtable}
}

\textbf{Python} is the most popular language due to its simplicity and
extensive libraries.

\textbf{Scikit-learn} provides simple tools for data mining and
analysis, perfect for beginners.

\textbf{TensorFlow} and \textbf{PyTorch} are advanced frameworks for
deep learning applications.

\textbf{Jupyter Notebook} offers interactive development environment for
experimentation.

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph LR
    A[Data] {-{-}{} B[Pandas/NumPy]}
    B {-{-}{} C[Scikit{-}learn]}
    C {-{-}{} D[Model]}
    D {-{-}{} E[Matplotlib]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\end{solutionbox}
\begin{mnemonicbox}
``Python Pandas Scikit Tensor Jupyter''

\end{mnemonicbox}
\subsection*{Question 2(a) [3 marks]}\label{q2a}

\textbf{Give the difference between Qualitative data and Quantitative
data.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Qualitative vs Quantitative Data}
\vspace{-10pt}
\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Qualitative Data & Quantitative Data \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Non-numerical} categories & \textbf{Numerical} values \\
Colors, names, grades & Height, weight, price \\
Cannot be measured & Can be measured \\
\end{longtable}
}

\textbf{Qualitative data} describes qualities or characteristics that
cannot be measured numerically.

\textbf{Quantitative data} represents measurable quantities expressed as
numbers.

\end{solutionbox}
\begin{mnemonicbox}
``Quality = Categories, Quantity = Numbers''

\end{mnemonicbox}
\subsection*{Question 2(b) [4 marks]}\label{q2b}

\textbf{Find the mean and median for the following data:
3,4,5,5,7,8,9,11,12,14.}

\begin{solutionbox}

\textbf{Given data:} 3, 4, 5, 5, 7, 8, 9, 11, 12, 14

\textbf{Mean calculation:}

\begin{itemize}
\tightlist
\item
  Sum = 3+4+5+5+7+8+9+11+12+14 = 78
\item
  Count = 10 numbers
\item
  \textbf{Mean = 78/10 = 7.8}
\end{itemize}

\textbf{Median calculation:}

\begin{itemize}
\tightlist
\item
  Data is already sorted
\item
  For 10 numbers: Median = (5th + 6th value)/2
\item
  \textbf{Median = (7+8)/2 = 7.5}
\end{itemize}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Results}
\vspace{-10pt}
\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Measure & Value \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Mean} & 7.8 \\
\textbf{Median} & 7.5 \\
\end{longtable}
}

\end{solutionbox}
\begin{mnemonicbox}
``Mean = Average, Median = Middle''

\end{mnemonicbox}
\subsection*{Question 2(c) [7 marks]}\label{q2c}

\textbf{Describe machine learning activities in detail.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Machine Learning Activities}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3125}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4062}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2812}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Activity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Data Collection} & Gathering relevant data & Survey responses \\
\textbf{Data Preprocessing} & Cleaning and preparing data & Removing
duplicates \\
\textbf{Feature Selection} & Choosing important variables & Age, income
for loans \\
\textbf{Model Training} & Teaching algorithm patterns & Feeding training
data \\
\textbf{Model Evaluation} & Testing model performance & Accuracy
measurement \\
\end{longtable}
}

\textbf{Data Collection} involves gathering information from various
sources like databases, sensors, or surveys.

\textbf{Data Preprocessing} includes cleaning, transforming, and
organizing raw data for analysis.

\textbf{Feature Selection} identifies the most relevant variables that
contribute to predictions.

\textbf{Model Training} uses algorithms to learn patterns from prepared
training data.

\textbf{Model Evaluation} tests how well the trained model performs on
new, unseen data.

\textbf{Diagram:}

\begin{verbatim}
flowchart LR
    A[Data Collection] {-{-} B[Data Preprocessing]}
    B {-{-} C[Feature Selection]}
    C {-{-} D[Model Training]}
    D {-{-} E[Model Evaluation]}
    E {-{-} F[Deployment]}
\end{verbatim}

\end{solutionbox}
\begin{mnemonicbox}
``Collect Process Feature Train Evaluate Deploy''

\end{mnemonicbox}
\subsection*{Question 2(a) OR [3
marks]}\label{q2a}

\textbf{Give the difference between predicative model and descriptive
model.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Predictive vs Descriptive Models}
\vspace{-10pt}
\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Predictive Model & Descriptive Model \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Forecasts} future outcomes & \textbf{Explains} current
patterns \\
Uses supervised learning & Uses unsupervised learning \\
Stock price prediction & Customer segmentation \\
\end{longtable}
}

\textbf{Predictive models} use historical data to make predictions about
future events or unknown outcomes.

\textbf{Descriptive models} analyze existing data to understand current
patterns and relationships.

\end{solutionbox}
\begin{mnemonicbox}
``Predict = Future, Describe = Present''

\end{mnemonicbox}
\subsection*{Question 2(b) OR [4
marks]}\label{q2b}

\textbf{Classify the following using appropriate data type: hair color,
gender, blood group type, time of day.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Data Type Classification}
\vspace{-10pt}
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Data & Type & Reason \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Hair color} & Nominal & Categories with no order \\
\textbf{Gender} & Nominal & Categories with no order \\
\textbf{Blood group} & Nominal & Categories with no order \\
\textbf{Time of day} & Continuous & Measurable quantity \\
\end{longtable}
}

\textbf{Nominal data} represents categories without any natural
ordering.

\textbf{Continuous data} can take any value within a range and is
measurable.

\end{solutionbox}
\begin{mnemonicbox}
``Names = Nominal, Numbers = Numerical''

\end{mnemonicbox}
\subsection*{Question 2(c) OR [7
marks]}\label{q2c}

\textbf{Explain various methods used in data pre-processing.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Data Preprocessing Methods}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3077}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3462}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3462}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Data Cleaning} & Remove errors and inconsistencies & Fix typos,
remove duplicates \\
\textbf{Data Integration} & Combine multiple sources & Merge customer
databases \\
\textbf{Data Transformation} & Convert to suitable format & Normalize
values 0-1 \\
\textbf{Data Reduction} & Reduce dataset size & Select important
features \\
\end{longtable}
}

\textbf{Data Cleaning} removes or corrects erroneous, incomplete, or
irrelevant data.

\textbf{Data Integration} combines data from multiple sources into a
unified dataset.

\textbf{Data Transformation} converts data into appropriate formats for
analysis.

\textbf{Data Reduction} decreases dataset size while maintaining
information quality.

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph LR
    A[Raw Data] {-{-}{} B[Data Cleaning]}
    B {-{-}{} C[Data Integration]}
    C {-{-}{} D[Data Transformation]}
    D {-{-}{} E[Data Reduction]}
    E {-{-}{} F[Processed Data]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\end{solutionbox}
\begin{mnemonicbox}
``Clean Integrate Transform Reduce''

\end{mnemonicbox}
\subsection*{Question 3(a) [3 marks]}\label{q3a}

\textbf{Give difference between classification and regression.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Classification vs Regression}
\vspace{-10pt}
\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Classification & Regression \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Discrete} output & \textbf{Continuous} output \\
Predicts categories & Predicts numerical values \\
Email: spam/not spam & House price prediction \\
\end{longtable}
}

\textbf{Classification} predicts discrete categories or classes from
input data.

\textbf{Regression} predicts continuous numerical values from input
data.

\end{solutionbox}
\begin{mnemonicbox}
``Class = Categories, Regress = Real numbers''

\end{mnemonicbox}
\subsection*{Question 3(b) [4 marks]}\label{q3b}

\textbf{Write confusion matrix using appropriate example. Calculate
accuracy and error rate for it.}

\begin{solutionbox}

\textbf{Example: Email Classification}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Confusion Matrix}
\vspace{-10pt}
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
& Predicted Spam & Predicted Not Spam \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Actual Spam} & 85 (TP) & 15 (FN) \\
\textbf{Actual Not Spam} & 10 (FP) & 90 (TN) \\
\end{longtable}
}

\textbf{Calculations:}

\begin{itemize}
\tightlist
\item
  \textbf{Accuracy = (TP+TN)/(TP+TN+FP+FN) = (85+90)/200 = 87.5\%}
\item
  \textbf{Error Rate = (FP+FN)/(TP+TN+FP+FN) = (10+15)/200 = 12.5\%}
\end{itemize}

\textbf{Key Terms:}

\begin{itemize}
\tightlist
\item
  \textbf{TP}: True Positive - Correctly predicted spam
\item
  \textbf{TN}: True Negative - Correctly predicted not spam
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``True Positive True Negative = Correct predictions''

\end{mnemonicbox}
\subsection*{Question 3(c) [7 marks]}\label{q3c}

\textbf{Explain KNN algorithm in detail.}

\begin{solutionbox}

\textbf{K-Nearest Neighbors (KNN)} is a simple classification algorithm
that classifies data points based on the majority class of their K
nearest neighbors.


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{KNN Algorithm Steps}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4643}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3214}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Choose K} & Select number of neighbors & K=3 \\
\textbf{Calculate Distance} & Find distance to all points & Euclidean
distance \\
\textbf{Find Neighbors} & Identify K closest points & 3 nearest
points \\
\textbf{Vote} & Majority class wins & 2 cats, 1 dog \rightarrow cat \\
\end{longtable}
}

\textbf{Working Process:}

\begin{enumerate}
\tightlist
\item
  \textbf{Calculate distances} between test point and all training
  points
\item
  \textbf{Sort distances} and select K nearest neighbors
\item
  \textbf{Count votes} from each class among neighbors
\item
  \textbf{Assign class} with majority votes
\end{enumerate}

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph LR
    A[New Data Point] {-{-}{} B[Calculate Distances]}
    B {-{-}{} C[Find K Nearest]}
    C {-{-}{} D[Majority Vote]}
    D {-{-}{} E[Predict Class]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\textbf{Advantages:}

\begin{itemize}
\tightlist
\item
  \textbf{Simple to implement} and understand
\item
  \textbf{No training required} - lazy learning algorithm
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``K Nearest Neighbors Vote for classification''

\end{mnemonicbox}
\subsection*{Question 3(a) OR [3
marks]}\label{q3a}

\textbf{Give any three applications of multiple linear regression.}

\begin{solutionbox}

\textbf{Applications of Multiple Linear Regression:}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Applications}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3939}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2727}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Application
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Variables
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{House Price Prediction} & Size, location, age & Estimate
property value \\
\textbf{Sales Forecasting} & Advertising, season, price & Predict
revenue \\
\textbf{Medical Diagnosis} & Symptoms, age, history & Risk assessment \\
\end{longtable}
}

\textbf{Multiple Linear Regression} uses multiple input variables to
predict a continuous output variable.

\end{solutionbox}
\begin{mnemonicbox}
``Multiple inputs, One output''

\end{mnemonicbox}
\subsection*{Question 3(b) OR [4
marks]}\label{q3b}

\textbf{Explain bagging, boosting and stacking in detail.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Ensemble Methods}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2963}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3704}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Bagging} & Parallel training, average results & Random Forest \\
\textbf{Boosting} & Sequential training, learn from errors & AdaBoost \\
\textbf{Stacking} & Meta-learner combines models & Neural network
combiner \\
\end{longtable}
}

\textbf{Bagging} trains multiple models on different data subsets and
averages predictions.

\textbf{Boosting} trains models sequentially, each learning from
previous model's mistakes.

\textbf{Stacking} uses a meta-model to learn how to combine predictions
from base models.

\end{solutionbox}
\begin{mnemonicbox}
``Bag parallel, Boost sequential, Stack meta''

\end{mnemonicbox}
\subsection*{Question 3(c) OR [7
marks]}\label{q3c}

\textbf{Explain single linear regression with its application.}

\begin{solutionbox}

\textbf{Single Linear Regression} finds the best straight line
relationship between one input variable (X) and one output variable (Y).

\textbf{Formula: Y = a + bX}

\begin{itemize}
\tightlist
\item
  \textbf{a}: Y-intercept
\item
  \textbf{b}: Slope of line
\end{itemize}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Application Example - House Price vs Size}
\vspace{-10pt}
\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
House Size (sq ft) & Price (lakhs) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1000 & 50 \\
1500 & 75 \\
2000 & 100 \\
\end{longtable}
}

\textbf{Working Process:}

\begin{enumerate}
\tightlist
\item
  \textbf{Collect data} with input-output pairs
\item
  \textbf{Plot points} on scatter graph
\item
  \textbf{Find best line} that minimizes error
\item
  \textbf{Make predictions} using line equation
\end{enumerate}

\textbf{Diagram:}

\begin{verbatim}
    Price |
          |    *
       75 |      *
          |        *
       50 |  *
          |\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
             1000  1500  Size
\end{verbatim}

\textbf{Applications:}

\begin{itemize}
\tightlist
\item
  \textbf{Sales vs Advertising}: More ads \rightarrow More sales
\item
  \textbf{Temperature vs Ice cream sales}: Hot weather \rightarrow More sales
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``One X predicts One Y with a line''

\end{mnemonicbox}
\subsection*{Question 4(a) [3 marks]}\label{q4a}

\textbf{Define the following: (1)support (2) confidence.}

\begin{solutionbox}

\textbf{Support} measures how frequently an itemset appears in the
dataset.

\textbf{Confidence} measures how often items in consequent appear when
antecedent is present.


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Definitions}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Measure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Support} & Count(itemset)/Total transactions & Bread appears in
60\% transactions \\
\textbf{Confidence} & Support(A\cupB)/Support(A) & 80\% who buy bread also
buy butter \\
\end{longtable}
}

\textbf{Support = Frequency of occurrence} \textbf{Confidence =
Reliability of rule}

\end{solutionbox}
\begin{mnemonicbox}
``Support = How often, Confidence = How reliable''

\end{mnemonicbox}
\subsection*{Question 4(b) [4 marks]}\label{q4b}

\textbf{Explain applications of unsupervised learning.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Unsupervised Learning Applications}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4194}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2903}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2903}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Application
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Customer Segmentation} & Group similar customers & Marketing
campaigns \\
\textbf{Data Compression} & Reduce data size & Image compression \\
\textbf{Anomaly Detection} & Find unusual patterns & Fraud detection \\
\textbf{Recommendation Systems} & Suggest similar items & Music
recommendations \\
\end{longtable}
}

\textbf{Customer Segmentation} groups customers with similar buying
behavior for targeted marketing.

\textbf{Data Compression} reduces storage space by finding patterns and
removing redundancy.

\textbf{Anomaly Detection} identifies unusual patterns that may indicate
fraud or errors.

\end{solutionbox}
\begin{mnemonicbox}
``Segment Compress Detect Recommend''

\end{mnemonicbox}
\subsection*{Question 4(c) [7 marks]}\label{q4c}

\textbf{Write and explain apriori algorithm with suitable example.}

\begin{solutionbox}

\textbf{Apriori Algorithm} finds frequent itemsets and generates
association rules for market basket analysis.


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Algorithm Steps}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4643}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3214}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Find frequent 1-itemsets} & Count individual items &
\{Bread\}:4, \{Milk\}:3 \\
\textbf{Generate 2-itemsets} & Combine frequent items &
\{Bread,Milk\}:2 \\
\textbf{Apply minimum support} & Filter infrequent sets & Keep if
support \geq 50\% \\
\textbf{Generate rules} & Create if-then rules & Bread \rightarrow Milk \\
\end{longtable}
}

\textbf{Example Dataset:}

\begin{itemize}
\tightlist
\item
  Transaction 1: \{Bread, Milk, Eggs\}
\item
  Transaction 2: \{Bread, Milk\}
\item
  Transaction 3: \{Bread, Eggs\}
\item
  Transaction 4: \{Milk, Eggs\}
\end{itemize}

\textbf{Working Process:}

\begin{enumerate}
\tightlist
\item
  \textbf{Scan database} to count item frequencies
\item
  \textbf{Generate candidate itemsets} of increasing size
\item
  \textbf{Prune infrequent itemsets} below minimum support
\item
  \textbf{Generate association rules} from frequent itemsets
\end{enumerate}

\textbf{Diagram:}

\begin{verbatim}
flowchart LR
    A[Transaction Database] {-{-} B[Find Frequent 1{-}itemsets]}
    B {-{-} C[Generate 2{-}itemsets]}
    C {-{-} D[Apply Min Support]}
    D {-{-} E[Generate Rules]}
\end{verbatim}

\end{solutionbox}
\begin{mnemonicbox}
``A-priori knowledge helps find frequent patterns''

\end{mnemonicbox}
\subsection*{Question 4(a) OR [3
marks]}\label{q4a}

\textbf{List out the difference between clustering and classification.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Clustering vs Classification}
\vspace{-10pt}
\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Clustering & Classification \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Unsupervised} learning & \textbf{Supervised} learning \\
No labeled data & Uses labeled training data \\
Groups similar data & Assigns predefined labels \\
\end{longtable}
}

\textbf{Clustering} discovers hidden groups in unlabeled data.

\textbf{Classification} assigns new data to known categories using
trained models.

\end{solutionbox}
\begin{mnemonicbox}
``Cluster = Groups unknown, Classify = Labels known''

\end{mnemonicbox}
\subsection*{Question 4(b) OR [4
marks]}\label{q4b}

\textbf{Explain the clustering process in detail.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Clustering Process Steps}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4643}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3214}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Data Preparation} & Clean and normalize data & Ensure quality
input \\
\textbf{Distance Metric} & Choose similarity measure & Euclidean,
Manhattan \\
\textbf{Algorithm Selection} & Pick clustering method & K-means,
Hierarchical \\
\textbf{Cluster Validation} & Evaluate cluster quality & Silhouette
score \\
\end{longtable}
}

\textbf{Clustering Process} groups similar data points together based on
their characteristics.

\textbf{Key decisions include choosing the number of clusters and
appropriate distance metrics.}

\textbf{Validation ensures clusters are meaningful and well-separated.}

\end{solutionbox}
\begin{mnemonicbox}
``Prepare Distance Algorithm Validate''

\end{mnemonicbox}
\subsection*{Question 4(c) OR [7
marks]}\label{q4c}

\textbf{Write and explain K-means clustering algorithm with suitable
example.}

\begin{solutionbox}

\textbf{K-means} partitions data into K clusters by minimizing
within-cluster sum of squares.


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Algorithm Steps}
\vspace{-10pt}
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Description & Example \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Initialize centroids} & Random K center points & C1(2,3),
C2(8,7) \\
\textbf{Assign points} & Each point to nearest centroid & Point(1,2) \rightarrow
C1 \\
\textbf{Update centroids} & Mean of assigned points & New C1(1.5,
2.5) \\
\textbf{Repeat} & Until centroids stop moving & Convergence \\
\end{longtable}
}

\textbf{Example: Customer Income vs Age}

\begin{itemize}
\tightlist
\item
  Customer 1: (Income=30k, Age=25)
\item
  Customer 2: (Income=35k, Age=30)
\item
  Customer 3: (Income=70k, Age=45)
\item
  Customer 4: (Income=75k, Age=50)
\end{itemize}

\textbf{Working Process:}

\begin{enumerate}
\tightlist
\item
  \textbf{Choose K=2} clusters for young/old customers
\item
  \textbf{Initialize centroids} randomly
\item
  \textbf{Calculate distances} from each customer to centroids
\item
  \textbf{Assign customers} to nearest centroid
\item
  \textbf{Update centroid positions} to center of assigned customers
\item
  \textbf{Repeat until stable}
\end{enumerate}

\textbf{Diagram:}

\begin{verbatim}
flowchart LR
    A[Choose K] {-{-} B[Initialize Centroids]}
    B {-{-} C[Assign Points to Nearest Centroid]}
    C {-{-} D[Update Centroid Positions]}
    D {-{-} E\{Converged?\}}
    E {-{-}|No| C}
    E {-{-}|Yes| F[Final Clusters]}
\end{verbatim}

\textbf{Advantages:}

\begin{itemize}
\tightlist
\item
  \textbf{Simple and fast} for large datasets
\item
  \textbf{Works well} with spherical clusters
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``K centroids Mean their assigned points''

\end{mnemonicbox}
\subsection*{Question 5(a) [3 marks]}\label{q5a}

\textbf{List the applications of matplotlib.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Matplotlib Applications}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4194}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2903}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2903}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Application
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Data Visualization} & Create charts and graphs & Bar charts,
histograms \\
\textbf{Scientific Plotting} & Research presentations & Mathematical
functions \\
\textbf{Dashboard Creation} & Interactive displays & Business metrics \\
\end{longtable}
}

\textbf{Matplotlib} is Python's primary plotting library for creating
static, animated, and interactive visualizations.

\textbf{Key features include support for multiple plot types and
customizable styling.}

\end{solutionbox}
\begin{mnemonicbox}
``Mat-plot-lib = Math Plotting Library''

\end{mnemonicbox}
\subsection*{Question 5(b) [4 marks]}\label{q5b}

\textbf{Write down code to plot a vertical line and horizontal line
using matplotlib.}

\begin{solutionbox}

\textbf{Code Block:}

\begin{verbatim}
import matplotlib.pyplot as plt

\# Create figure
plt.figure(figsize=(8, 6))

\# Plot vertical line at x=3
plt.axvline(x=3, color={red}, linestyle={{-}{-}}, label={Vertical Line})

\# Plot horizontal line at y=2
plt.axhline(y=2, color={blue}, linestyle={{-}}, label={Horizontal Line})

\# Add labels and title
plt.xlabel({X{-}axis})
plt.ylabel({Y{-}axis})
plt.title({Vertical and Horizontal Lines})
plt.legend()
plt.grid(True)
plt.show()
\end{verbatim}

\textbf{Key Functions:}

\begin{itemize}
\tightlist
\item
  \textbf{axvline()}: Creates vertical line
\item
  \textbf{axhline()}: Creates horizontal line
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``axvline = Vertical, axhline = Horizontal''

\end{mnemonicbox}
\subsection*{Question 5(c) [7 marks]}\label{q5c}

\textbf{Explain features and applications of Scikit-Learn.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Scikit-Learn Features}
\vspace{-10pt}
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Description & Example \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Simple API} & Easy to use interface & fit(), predict() \\
\textbf{Multiple Algorithms} & Various ML methods & SVM, Random
Forest \\
\textbf{Data Preprocessing} & Built-in data tools & StandardScaler \\
\textbf{Model Evaluation} & Performance metrics & accuracy\_score \\
\end{longtable}
}

\textbf{Scikit-Learn} is Python's most popular machine learning library
providing simple tools for data analysis.

\textbf{Key Strengths:}

\begin{itemize}
\tightlist
\item
  \textbf{Consistent interface} across all algorithms
\item
  \textbf{Excellent documentation} with examples
\item
  \textbf{Active community} support and development
\end{itemize}

\textbf{Applications:}

\begin{itemize}
\tightlist
\item
  \textbf{Classification}: Email spam detection
\item
  \textbf{Regression}: House price prediction
\item
  \textbf{Clustering}: Customer segmentation
\item
  \textbf{Dimensionality Reduction}: Data visualization
\end{itemize}

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph TD
    A[Scikit{-Learn] {-}{-}{} B[Classification]}
    A {-{-}{} C[Regression]}
    A {-{-}{} D[Clustering]}
    A {-{-}{} E[Preprocessing]}
    B {-{-}{} F[SVM, Decision Trees]}
    C {-{-}{} G[Linear, Polynomial]}
    D {-{-}{} H[K{-}means, DBSCAN]}
    E {-{-}{} I[Scaling, Encoding]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\end{solutionbox}
\begin{mnemonicbox}
``Scikit = Science Kit for machine learning''

\end{mnemonicbox}
\subsection*{Question 5(a) OR [3
marks]}\label{q5a}

\textbf{Give the purpose of NumPy in machine learning.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{NumPy Purpose in ML}
\vspace{-10pt}
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2903}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4194}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2903}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Benefit
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Numerical Computing} & Fast array operations & Efficient
calculations \\
\textbf{Foundation Library} & Base for other libraries & Pandas,
Scikit-learn use it \\
\textbf{Mathematical Functions} & Built-in math operations & Statistics,
linear algebra \\
\end{longtable}
}

\textbf{NumPy} provides the foundation for numerical computing in Python
machine learning applications.

\textbf{Essential for handling large datasets and performing
mathematical operations efficiently.}

\end{solutionbox}
\begin{mnemonicbox}
``Num-Py = Numerical Python''

\end{mnemonicbox}
\subsection*{Question 5(b) OR [4
marks]}\label{q5b}

\textbf{Write down steps to import csv file in pandas.}

\begin{solutionbox}

\textbf{Code Block:}

\begin{verbatim}
import pandas as pd

\# Step 1: Import pandas library
\# Step 2: Use read\_csv() function
data = pd.read\_csv({filename.csv})

\# Step 3: Display first few rows
print(data.head())

\# Optional: Specify parameters
data = pd.read\_csv({file.csv}, 
                   delimiter={,},
                   header=0,
                   index\_col=0)
\end{verbatim}

\textbf{Steps:}

\begin{enumerate}
\tightlist
\item
  \textbf{Import pandas} library
\item
  \textbf{Use read\_csv()} function with filename
\item
  \textbf{Verify data} with head() method
\end{enumerate}

\end{solutionbox}
\begin{mnemonicbox}
``Import Read Verify''

\end{mnemonicbox}
\subsection*{Question 5(c) OR [7
marks]}\label{q5c}

\textbf{Explain features and applications of Pandas.}

\begin{solutionbox}


{\def\LTcaptype{none} % do not increment counter
\vspace{-5pt}
\captionof{table}{Pandas Features}
\vspace{-10pt}
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Description & Example \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Data Structures} & DataFrame and Series & Tabular data
handling \\
\textbf{Data I/O} & Read/write multiple formats & CSV, Excel, JSON \\
\textbf{Data Cleaning} & Handle missing values & dropna(), fillna() \\
\textbf{Data Analysis} & Statistical operations & groupby(),
describe() \\
\end{longtable}
}

\textbf{Pandas} is the primary data manipulation library in Python for
machine learning projects.

\textbf{Key Capabilities:}

\begin{itemize}
\tightlist
\item
  \textbf{Data Loading} from various file formats
\item
  \textbf{Data Cleaning} and preprocessing operations
\item
  \textbf{Data Transformation} and reshaping
\item
  \textbf{Statistical Analysis} and aggregation
\end{itemize}

\textbf{Applications:}

\begin{itemize}
\tightlist
\item
  \textbf{Data Preprocessing}: Clean datasets before ML
\item
  \textbf{Exploratory Analysis}: Understand data patterns
\item
  \textbf{Feature Engineering}: Create new variables
\item
  \textbf{Data Integration}: Merge multiple data sources
\end{itemize}

\textbf{Diagram:}

\begin{center}
\textbf{Mermaid Diagram (Code)}
\begin{verbatim}
{Shaded}
{Highlighting}[]
graph LR
    A[Raw Data] {-{-}{} B[Pandas DataFrame]}
    B {-{-}{} C[Data Cleaning]}
    C {-{-}{} D[Data Analysis]}
    D {-{-}{} E[Feature Engineering]}
    E {-{-}{} F[ML Ready Data]}
{Highlighting}
{Shaded}
\end{verbatim}
\end{center}

\textbf{Advantages:}

\begin{itemize}
\tightlist
\item
  \textbf{Intuitive syntax} for data operations
\item
  \textbf{High performance} with optimized operations
\item
  \textbf{Integration} with other ML libraries
\end{itemize}

\end{solutionbox}
\begin{mnemonicbox}
``Pandas = Panel Data for analysis''

\end{mnemonicbox}

\end{document}
